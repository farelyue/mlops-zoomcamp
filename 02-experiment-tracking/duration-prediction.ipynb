{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f08614d",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41062d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modelling\n",
    "import pickle\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "# Experiment tracking\n",
    "import mlflow\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a373aa",
   "metadata": {},
   "source": [
    "### Set up experiment tracking with MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1464985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store experiment files on the database\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "\n",
    "# Create a new experiment\n",
    "mlflow.set_experiment(\"duration-trip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d82f4a",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9e6479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform nyc-taxi dataset\n",
    "def read_dataframe(file_path):\n",
    "\n",
    "    # Load csv dataset\n",
    "    df = pd.read_parquet(file_path)\n",
    "\n",
    "    # Convert pick up and drop off location into string format\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    # Convert pick up and drop off time column into datetime format\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "\n",
    "    # Add duration column, differences between pick up and drop off time\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    \n",
    "    # Convert duration column into minute format\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    # Filter duration between 1 and 60 minutes\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8029eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data train and validation\n",
    "df_train_path = 'data/green_tripdata_2021-01.parquet'\n",
    "df_val_path = 'data/green_tripdata_2021-02.parquet'\n",
    "\n",
    "df_train = read_dataframe(df_train_path)\n",
    "df_val = read_dataframe(df_val_path)\n",
    "\n",
    "print(f'Dimension of data train : {df_train.shape[0]}, {df_train.shape[1]}')\n",
    "print(f'Dimension of data validation : {df_val.shape[0]}, {df_val.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8be0bac",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75f8383",
   "metadata": {},
   "source": [
    "Feature engineering experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "951d51ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering to concatenate pick up and drop off location id\n",
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc215a4",
   "metadata": {},
   "source": [
    "Preparation for data train and data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5cbfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical and numerical columns\n",
    "categorical = ['PU_DO']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "# Instantiate dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "\n",
    "# Fit and transform data train into vectors with feature-value format\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "# Transform data validation into vectors based on pattern got from data train\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "# Define target column for predicting\n",
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9fb68b",
   "metadata": {},
   "source": [
    "### Modelling with MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca00a5a0",
   "metadata": {},
   "source": [
    "#### 1. Experiment without MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f286ec40",
   "metadata": {},
   "source": [
    "Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429e2394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "mean_squared_error(y_val, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f58aff4",
   "metadata": {},
   "source": [
    "Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24908286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lasso.predict(X_val)\n",
    "\n",
    "mean_squared_error(y_val, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d517c",
   "metadata": {},
   "source": [
    "Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe335aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ridge.predict(X_val)\n",
    "\n",
    "mean_squared_error(y_val, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78503aa",
   "metadata": {},
   "source": [
    "#### 2. Experiment tracking without parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997d0836",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f657c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression\n",
    "\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Log general info, ex : developer_name\n",
    "    mlflow.set_tag(\"developer\", \"farel\")\n",
    "    mlflow.set_tag(\"model\", \"linear-regression\")\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"train-data-path\", df_train_path)\n",
    "    mlflow.log_param(\"validation-data-path\", df_val_path)\n",
    "    \n",
    "    # Training model\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    # mlflow.sklearn.log_model(lr, 'Linear Regression')\n",
    "    \n",
    "    y_pred = lr.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "    # Keep info related to metrics resulted from the model\n",
    "    mlflow.log_metric(\"rmse\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bead68a",
   "metadata": {},
   "source": [
    "Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52c0fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression\n",
    "\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Log general info, ex : developer_name\n",
    "    mlflow.set_tag(\"developer\", \"farel\")\n",
    "    mlflow.set_tag(\"model\", \"lasso-regression\")\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"train-data-path\", df_train_path)\n",
    "    mlflow.log_param(\"validation-data-path\", df_val_path)\n",
    "    \n",
    "    # Log model\n",
    "    l1 = Lasso()\n",
    "    l1.fit(X_train, y_train)\n",
    "    # mlflow.sklearn.log_model(l1, 'Lasso Regression')\n",
    "    \n",
    "    y_pred = l1.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "    # To keep info related to metrics resulted from the model\n",
    "    mlflow.log_metric(\"rmse\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9846a73d",
   "metadata": {},
   "source": [
    "Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe20683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression\n",
    "\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Log general info, ex : developer_name\n",
    "    mlflow.set_tag(\"developer\", \"farel\")\n",
    "    mlflow.set_tag(\"model\", \"ridge-regression\")\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"train-data-path\", df_train_path)\n",
    "    mlflow.log_param(\"validation-data-path\", df_val_path)\n",
    "    \n",
    "    # Log model\n",
    "    l2 = Ridge()\n",
    "    l2.fit(X_train, y_train)\n",
    "    # mlflow.sklearn.log_model(l2, 'Ridge Regression')\n",
    "    \n",
    "    y_pred = l2.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "    # To keep info related to metrics resulted from the model\n",
    "    mlflow.log_metric(\"rmse\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d07fa9f",
   "metadata": {},
   "source": [
    "#### 3. Experiment MLFlow with single parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a033e83d",
   "metadata": {},
   "source": [
    "Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff39cc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression\n",
    "\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Log general info, ex : developer_name\n",
    "    mlflow.set_tag(\"developer\", \"farel\")\n",
    "    mlflow.set_tag(\"model\", \"lasso-regression\")\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"train-data-path\", df_train_path)\n",
    "    mlflow.log_param(\"validation-data-path\", df_val_path)\n",
    "    \n",
    "    alpha = 0.1\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "\n",
    "    # Training model\n",
    "    l1 = Lasso(alpha=alpha)\n",
    "    l1.fit(X_train, y_train)\n",
    "    # mlflow.sklearn.log_model(l1, 'Lasso Regression')\n",
    "    \n",
    "    y_pred = l1.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "    # Keep info related to metrics resulted from the model\n",
    "    mlflow.log_metric(\"rmse\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d4eaa1",
   "metadata": {},
   "source": [
    "Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "defe0cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression\n",
    "\n",
    "with mlflow.start_run():\n",
    "    \n",
    "    # Log general info, ex : developer_name\n",
    "    mlflow.set_tag(\"developer\", \"farel\")\n",
    "    mlflow.set_tag(\"model\", \"ridge-regression\")\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"train-data-path\", df_train_path)\n",
    "    mlflow.log_param(\"validation-data-path\", df_val_path)\n",
    "    \n",
    "    alpha = 0.1\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "\n",
    "    # Training model\n",
    "    l2 = Ridge(alpha=alpha)\n",
    "    l2.fit(X_train, y_train)\n",
    "    # mlflow.sklearn.log_model(l2, 'Ridge Regression')\n",
    "    \n",
    "    y_pred = l2.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "    # Keep info related to metrics resulted from the model\n",
    "    mlflow.log_metric(\"rmse\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65544246",
   "metadata": {},
   "source": [
    "#### 4. Experiment tracking with multiple parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abd661da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression\n",
    "alphas = [0.1, 0.01, 0.001]\n",
    "for alpha in alphas:\n",
    "    with mlflow.start_run():\n",
    "        # Log general info, ex : developer_name\n",
    "        mlflow.set_tag(\"developer\", \"farel\")\n",
    "        mlflow.set_tag(\"model\", \"lasso-regression\")\n",
    "        mlflow.set_tag(\"experiment\", \"multiple-parameters\")        \n",
    "\n",
    "        # Log a parameter\n",
    "        mlflow.log_param(\"train-data-path\", df_train_path)\n",
    "        mlflow.log_param(\"validation-data-path\", df_val_path)\n",
    "        mlflow.log_param(\"alpha\", alpha)\n",
    "        \n",
    "        # Train model\n",
    "        l1 = Lasso(alpha=alpha)\n",
    "        l1.fit(X_train, y_train)\n",
    "        # mlflow.sklearn.log_model(l1, 'Lasso Regression')\n",
    "        \n",
    "        # Evaluate model\n",
    "        y_pred = l1.predict(X_val)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"rmse\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626d7671",
   "metadata": {},
   "source": [
    "Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4698fe06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression\n",
    "alphas = [0.1, 0.01, 0.001]\n",
    "for alpha in alphas:\n",
    "    with mlflow.start_run():\n",
    "        # Log general info, ex : developer_name\n",
    "        mlflow.set_tag(\"developer\", \"farel\")\n",
    "        mlflow.set_tag(\"model\", \"ridge-regression\")\n",
    "        mlflow.set_tag(\"experiment\", \"multiple-parameters\")        \n",
    "\n",
    "        # Log a parameter\n",
    "        mlflow.log_param(\"train-data-path\", df_train_path)\n",
    "        mlflow.log_param(\"validation-data-path\", df_val_path)\n",
    "        mlflow.log_param(\"alpha\", alpha)\n",
    "        \n",
    "        # Train model\n",
    "        l2 = Ridge(alpha=alpha)\n",
    "        l2.fit(X_train, y_train)\n",
    "        # mlflow.sklearn.log_model(l2, 'Ridge Regression')\n",
    "        \n",
    "        # Evaluate model\n",
    "        y_pred = l2.predict(X_val)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"rmse\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8086c9e0",
   "metadata": {},
   "source": [
    "#### 5. XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265c35bc",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "091ab328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data train and validation into optimized DMatrix format\n",
    "train = xgb.DMatrix(X_train, label=y_train)\n",
    "valid = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2d84b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define objective function for training xgboost model using MLflow\n",
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        # Log general info\n",
    "        mlflow.set_tag(\"developer\", \"farel\")\n",
    "        mlflow.set_tag(\"model\", \"xgboost\")\n",
    "        mlflow.set_tag(\"experiment\", \"tuning-hyperparams\")        \n",
    "\n",
    "        # Log batch of parameters\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Train model\n",
    "        booster = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=100,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "\n",
    "        # Evaluate model\n",
    "        y_pred = booster.predict(valid)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd374942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters combination\n",
    "search_space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "    'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "    'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "    'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective': 'reg:linear',\n",
    "    'seed': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f6f2be",
   "metadata": {},
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1f77f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call objective function to running xgboost model\n",
    "best_result = fmin(\n",
    "    fn=objective,\n",
    "    space=search_space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=Trials(),\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fff2a2",
   "metadata": {},
   "source": [
    "Find Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8244f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best parameters from run experiment\n",
    "best_run_id = mlflow.search_runs(\n",
    "    filter_string=\"tags.model='xgboost' and tags.experiment='tuning-hyperparams'\",\n",
    "    order_by=[\"metrics.rmse\"],\n",
    "    max_results=1\n",
    ").run_id\n",
    "\n",
    "best_params = mlflow.get_run(best_run_id[0]).data.params\n",
    "best_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023b6d2b",
   "metadata": {},
   "source": [
    "Training Model with Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a88bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do autologging using mlflow built-in function\n",
    "mlflow.xgboost.autolog()\n",
    "\n",
    "# Train model\n",
    "booster = xgb.train(\n",
    "    params=best_params,\n",
    "    dtrain=train,\n",
    "    num_boost_round=100,\n",
    "    evals=[(valid, 'validation')],\n",
    "    early_stopping_rounds=50\n",
    ")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-tracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
