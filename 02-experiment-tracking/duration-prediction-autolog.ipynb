{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Utilization\n",
    "from pprint import pprint\n",
    "\n",
    "# Modelling\n",
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "import pickle\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up experiment tracking with MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location=('/Users/farelyue/Documents/Projects/Data '\n",
       " 'Science/mlops-zoomcamp/02-experiment-tracking/mlruns/2'), creation_time=1728400989576, experiment_id='2', last_update_time=1728400989576, lifecycle_stage='active', name='duration-trip-autolog', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store experiment files on the database\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "\n",
    "# Create a new experiment\n",
    "mlflow.set_experiment(\"duration-trip-autolog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform nyc-taxi dataset\n",
    "def read_dataframe(file_path):\n",
    "\n",
    "    # Load csv dataset\n",
    "    df = pd.read_parquet(file_path)\n",
    "\n",
    "    # Convert pick up and drop off location into string format\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    # Convert pick up and drop off time column into datetime format\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "\n",
    "    # Add duration column, differences between pick up and drop off time\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    \n",
    "    # Convert duration column into minute format\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    # Filter duration between 1 and 60 minutes\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Fetch logged params, metrics, and model\n",
    "def fetch_logged_data(run_id):\n",
    "    client = MlflowClient()\n",
    "    data = client.get_run(run_id).data\n",
    "\n",
    "    params = data.params\n",
    "    metrics = data.metrics\n",
    "    tags = {k:v for k, v in data.tags.items() if not k.startswith('mlflow.')}\n",
    "    artifacts = [f.path for f in client.list_artifacts(run_id, \"model\")]\n",
    "\n",
    "    return params, metrics, tags, artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of data train : 73908, 21\n",
      "Dimension of data validation : 61921, 21\n"
     ]
    }
   ],
   "source": [
    "# Load data train and validation\n",
    "df_train_path = 'data/green_tripdata_2021-01.parquet'\n",
    "df_val_path = 'data/green_tripdata_2021-02.parquet'\n",
    "\n",
    "df_train = read_dataframe(df_train_path)\n",
    "df_val = read_dataframe(df_val_path)\n",
    "\n",
    "print(f'Dimension of data train : {df_train.shape[0]}, {df_train.shape[1]}')\n",
    "print(f'Dimension of data validation : {df_val.shape[0]}, {df_val.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering to concatenate pick up and drop off location id\n",
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation for data train and data validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical and numerical columns\n",
    "categorical = ['PU_DO']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "# Instantiate dictionary vectorizer\n",
    "dv = DictVectorizer()\n",
    "\n",
    "# Fit and transform data train into vectors with feature-value format\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "# Transform data validation into vectors based on pattern got from data train\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "# Define target column for predicting\n",
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save DictVectorizer preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models folder\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save DictVectorizer preprocessor object into binary format for later use\n",
    "with open('models/preprocessor.b', 'wb') as f_out:\n",
    "    pickle.dump(dv, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling with MLflow autolog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the random_state\n",
    "RANDOM_STATE = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/20 15:43:37 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Run ID': '3982aae14ad24edca76cf903b45350d9', 'rmse': 6.914909840472828}\n"
     ]
    }
   ],
   "source": [
    "# Enable autologging\n",
    "mlflow.sklearn.autolog(log_datasets=False)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "\n",
    "    # Set tag of developer\n",
    "    mlflow.set_tag('developer','farelyue')\n",
    "\n",
    "    # Log batch of params\n",
    "    params = {\n",
    "        'train-data-path':'./data/green_tripdata_2021-01.parquet',\n",
    "        'validation-data-path':'./data/green_tripdata_2021-02.parquet'\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # Log artifacts\n",
    "    mlflow.log_artifact(local_path='models/preprocessor.b', artifact_path='preprocessor')\n",
    "\n",
    "    # Train the model\n",
    "    rf = RandomForestRegressor(random_state=RANDOM_STATE)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the validation dataset\n",
    "    y_pred = rf.predict(X_val)\n",
    "\n",
    "    # Evaluate model and log the metrics\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metrics({'rmse':rmse})\n",
    "    \n",
    "    print({'Run ID':run.info.run_id, 'rmse':rmse})    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/20 15:51:54 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Run ID': '668dbd3cd12547428e8fd65c5b4ae3d6', 'rmse': 6.742303328497426}\n"
     ]
    }
   ],
   "source": [
    "# Enable autologging\n",
    "mlflow.sklearn.autolog(log_datasets=False)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "\n",
    "    # Set tag of developer\n",
    "    mlflow.set_tag('developer','farelyue')\n",
    "\n",
    "    # Log batch of params\n",
    "    params = {\n",
    "        'train-data-path':'./data/green_tripdata_2021-01.parquet',\n",
    "        'validation-data-path':'./data/green_tripdata_2021-02.parquet'\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # Log artifacts\n",
    "    mlflow.log_artifact(local_path='models/preprocessor.b', artifact_path='preprocessor')\n",
    "\n",
    "    # Train the model\n",
    "    gbr = GradientBoostingRegressor(random_state=RANDOM_STATE)\n",
    "    gbr.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the validation dataset\n",
    "    y_pred = gbr.predict(X_val)\n",
    "\n",
    "    # Evaluate model and log the metrics\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metrics({'rmse':rmse})\n",
    "    \n",
    "    print({'Run ID':run.info.run_id, 'rmse':rmse})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Extra Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/20 15:51:58 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Run ID': '794703933ee54ea79264b8d27cea1959', 'rmse': 6.940426720605602}\n"
     ]
    }
   ],
   "source": [
    "# Enable autologging\n",
    "mlflow.sklearn.autolog(log_datasets=False)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "\n",
    "    # Set tag of developer\n",
    "    mlflow.set_tag('developer','farelyue')\n",
    "\n",
    "    # Log batch of params\n",
    "    params = {\n",
    "        'train-data-path':'./data/green_tripdata_2021-01.parquet',\n",
    "        'validation-data-path':'./data/green_tripdata_2021-02.parquet'\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # Log artifacts\n",
    "    mlflow.log_artifact(local_path='models/preprocessor.b', artifact_path='preprocessor')\n",
    "\n",
    "    # Train the model\n",
    "    etr = ExtraTreesRegressor(random_state=RANDOM_STATE)\n",
    "    etr.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the validation dataset\n",
    "    y_pred = etr.predict(X_val)\n",
    "\n",
    "    # Evaluate model and log the metrics\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metrics({'rmse':rmse})\n",
    "    \n",
    "    print({'Run ID':run.info.run_id, 'rmse':rmse})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. SVM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/20 16:14:00 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Run ID': '47e45a45a4e441afa61e6e23cc7624c2', 'rmse': 807.9904772805995}\n"
     ]
    }
   ],
   "source": [
    "# Enable autologging\n",
    "mlflow.sklearn.autolog(log_datasets=False)\n",
    " \n",
    "with mlflow.start_run() as run:\n",
    "    \n",
    "    # Set tag of developer\n",
    "    mlflow.set_tag('developer','farelyue')\n",
    "\n",
    "    # Log batch of params\n",
    "    params = {\n",
    "        'train-data-path':'./data/green_tripdata_2021-01.parquet',\n",
    "        'validation-data-path':'./data/green_tripdata_2021-02.parquet'\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # Log artifacts\n",
    "    mlflow.log_artifact(local_path='models/preprocessor.b', artifact_path='preprocessor')\n",
    "\n",
    "    # Train the model\n",
    "    svr = LinearSVR(random_state=RANDOM_STATE)\n",
    "    svr.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on the validation dataset\n",
    "    y_pred = svr.predict(X_val)\n",
    "\n",
    "    # Evaluate model and log the metrics\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metrics({'rmse':rmse})\n",
    "    \n",
    "    print({'Run ID':run.info.run_id, 'rmse':rmse})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/20 16:25:23 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of sklearn. If you encounter errors during autologging, try upgrading / downgrading sklearn to a supported version, or try upgrading MLflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Run ID': 'b09242a9964c4965bc8baa572bc2103b', 'rmse': 6.644320289321216}\n"
     ]
    }
   ],
   "source": [
    "# Enable autologging\n",
    "mlflow.sklearn.autolog(log_datasets=False)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "\n",
    "    # Set tag of developer\n",
    "    mlflow.set_tag('developer','farelyue')\n",
    "    mlflow.set_tag('estimator_name', 'XGBRegressor')\n",
    "\n",
    "    # Log batch of params\n",
    "    params = {\n",
    "        'train-data-path':'./data/green_tripdata_2021-01.parquet',\n",
    "        'validation-data-path':'./data/green_tripdata_2021-02.parquet'\n",
    "    }\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # Log artifacts\n",
    "    mlflow.log_artifact(local_path='models/preprocessor.b', artifact_path='preprocessor')\n",
    "\n",
    "    # Train the model\n",
    "    xgbr = xgb.XGBRegressor(random_state=RANDOM_STATE)\n",
    "    xgbr.fit(X_train, y_train)\n",
    "    mlflow.log_params(xgbr.get_params())\n",
    "    mlflow.sklearn.log_model(xgbr, artifact_path='model')\n",
    "\n",
    "    # Predict on the validation dataset\n",
    "    y_pred = xgbr.predict(X_val)\n",
    "\n",
    "    # Evaluate model and log the metrics\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metrics({'rmse':rmse})\n",
    "    \n",
    "    print({'Run ID':run.info.run_id, 'rmse':rmse})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-tracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
