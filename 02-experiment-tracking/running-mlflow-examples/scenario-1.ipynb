{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1: A single data scientist participating in an ML competition\n",
    "\n",
    "MLflow setup:\n",
    "* Tracking server: no\n",
    "* Backend store: local filesystem\n",
    "* Artifacts store: local filesystem\n",
    "\n",
    "The experiments can be explored locally by launching the MLflow UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from mlflow.exceptions import MlflowException\n",
    "from mlflow.store.artifact.runs_artifact_repo import RunsArtifactRepository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up tracking URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'file:///Users/farelyue/Documents/Projects/Data%20Science/mlops-zoomcamp/02-experiment-tracking/running-mlflow-examples/mlruns'\n"
     ]
    }
   ],
   "source": [
    "# Display default tracking uri\n",
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List down all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment id : 0, experiment name : Default\n"
     ]
    }
   ],
   "source": [
    "# Lost down all experiments before do an experiment\n",
    "experiments = mlflow.search_experiments()\n",
    "for experiment in experiments:\n",
    "    print(f\"experiment id : {experiment.experiment_id}, experiment name : {experiment.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an experiment and logging a new run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/23 23:18:41 INFO mlflow.tracking.fluent: Experiment with name 'exp_scenario_1' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default artifacts URI: 'file:///Users/farelyue/Documents/Projects/Data%20Science/mlops-zoomcamp/02-experiment-tracking/running-mlflow-examples/mlruns/308051317503925502/5dfce563ab44448c94890830e616bc91/artifacts'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/exp-tracking/lib/python3.9/site-packages/_distutils_hack/__init__.py:11: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/exp-tracking/lib/python3.9/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "# Create a new experiment\n",
    "mlflow.set_experiment(\"exp_scenario_1\")\n",
    "\n",
    "# Track our training model process\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Load iris dataset\n",
    "    X, y = load_iris(return_X_y=True)\n",
    "\n",
    "    # Log the params\n",
    "    params = {\"C\": 0.1, \"random_state\": 42}\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Training model\n",
    "    lr = LogisticRegression(**params).fit(X, y)\n",
    "    y_pred = lr.predict(X)\n",
    "\n",
    "    # Log the metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy_score(y, y_pred))\n",
    "\n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(lr, artifact_path=\"models\")\n",
    "    \n",
    "    # Display the artifact uri\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment id : 308051317503925502, experiment name : exp_scenario_1\n",
      "experiment id : 0, experiment name : Default\n"
     ]
    }
   ],
   "source": [
    "# Lost down all experiments after do an experiment\n",
    "experiments = mlflow.search_experiments()\n",
    "for experiment in experiments:\n",
    "    print(f\"experiment id : {experiment.experiment_id}, experiment name : {experiment.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with the model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1729702082039, current_stage='None', description='new version of scenario_1 model', last_updated_timestamp=1729702082039, name='scenario_1', run_id='5dfce563ab44448c94890830e616bc91', run_link=None, source='file:///Users/farelyue/Documents/Projects/Data%20Science/mlops-zoomcamp/02-experiment-tracking/running-mlflow-examples/mlruns/308051317503925502/5dfce563ab44448c94890830e616bc91/artifacts/models', status='READY', status_message=None, tags={}, user_id=None, version=1>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate client for manage experiments and runs\n",
    "client = MlflowClient()\n",
    "\n",
    "registered_model_name = 'scenario_1'\n",
    "\n",
    "# Register model name in the model registry\n",
    "client.create_registered_model(name=registered_model_name)\n",
    "\n",
    "# Create new version of model name\n",
    "desc = 'new version of scenario_1 model'\n",
    "\n",
    "# Get experiment id by experiment name\n",
    "experiment_name = 'exp_scenario_1'\n",
    "experiment = mlflow.get_experiment_by_name(name=experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "# Get run id\n",
    "run_id = mlflow.search_runs(experiment_ids=experiment_id)['run_id'].values[0]\n",
    "\n",
    "# Run URI\n",
    "runs_uri =f\"runs:/{run_id}/models\"\n",
    "\n",
    "# Source artifacts\n",
    "model_src = RunsArtifactRepository.get_underlying_uri(runs_uri)\n",
    "\n",
    "# Create a new model version\n",
    "client.create_model_version(name=registered_model_name, source=model_src, run_id=run_id, description=desc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exp-tracking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
